\chapter{Обзор}\label{ch:ch1}

\section{История автоматического анализа программ}\label{sec:ch1/sec1}
% Ранняя история верификации программ
%TODO: add references
В 1947 году появились термины «ошибка» (bug) и «отладка» (debugging). Грейс Мюррей, 
ученая из Гарвардского университета, работавшая с компьютером Mark II, обнаружила, 
что мотылек застрял в реле, из-за чего оно не вступало в контакт. Она подробно 
описала инцидент в рабочем журнале, приклеив мотылька лентой в качестве доказательства и 
назвав мотылька «ошибкой», вызывающей ошибку, а действие по устранению ошибки - «отладкой».
%TODO: reformulate bug

В то время тесты были сосредоточены на оборудовании, потому что оно было не так развито, как 
сегодня, и его надежность была важна для правильного функционирования программного обеспечения.
Термин отладка был связан с применением исправлений для конкретной ошибки как одна из фаз в 
стадии разработки программного обеспечения. Проводимые тесты имели коррекционный характер и 
выполнялись для устранения ошибок, не дававших программе работать. 

В 1957 году Чарльз Бейкер объясняет необходимость разработки тестов, чтобы гарантировать, что 
программное обеспечение соответствует заранее разработанным требованиям (тестирование), а также 
функциональным возможностям программы (отладка). Разработка тестов стала более важной по мере 
того, как разрабатывались более дорогие и сложные приложения, и стоимость устранения всех этих 
недостатков оказывала явный риск для прибыльности проекта. Особое внимание было уделено 
увеличению количества и качества тестов, и впервые качество продукта стало связано с фазой 
тестирования. Цель заключалась в том, чтобы продемонстрировать, что программа выполняет то, что 
от нее требовалось, с использованием ожидаемых и выдаваемых параметров.

В 1979 году Гленфорд Дж. Майерс радикально меняет процедуру обнаружения ошибок в программе:
"Тестирование программного обеспечения - это процесс запуска программы с целью поиска ошибок."
Обеспокоенность Майерса заключалась в том, что, преследуя цель продемонстрировать, что программа 
безупречна, можно подсознательно выбрать тестовые данные, которые имеют низкую вероятность 
вызвать сбои программы, тогда как если цель состоит в том, чтобы продемонстрировать, что 
программа ошибочна, тестовые данные будут имеют большую вероятность их обнаружения, и мы будем 
более успешными в тестировании и, следовательно, в качестве программного обеспечения. C этого
момента тесты будут пытаться продемонстрировать, что программа не работает должным образом, в 
отличие от того, как это делалось ранее, что приведет к новым методам тестирования и анализа.

В 1983 году была предложена методология, которая объединяет действия по анализу, пересмотру 
(revision) и тестированию в течение жизненного цикла программного обеспечения, чтобы получить 
оценку продукта в процессе разработки. Этап тестирования признан неотъемлемым этапом в 
разработке продукта, приобретая особое значение в связи с появлением инструментов для разработки 
автоматизированных тестов, которые заметно повысили эффективность.

В 1988 году Уильям Хетцель опубликовал «Рост тестирования программного обеспечения», в котором 
он переопределил концепцию тестирования как планирование, проектирование, создание, обслуживание 
и выполнение тестов и тестовых сред. Это  в основном отразилось на появлении фазы тестирования 
на самом раннем этапе разработки продукта, этапе планирования. Если мы представим весь процесс 
разработки в виде конечной линии, где начало - это планирование, а конец - мониторинг проданного 
продукта, мы увидим, как фаза тестирования переместилась влево. Онa появилась как этап пост-
продакшнен, позже это был этап предпродакшн, а сейчас она находится на стадии завершения. Эта 
практика известна как Shift-Left.

Э. В. Дейкстра в лекции «О надёжности программ» утверждает, что тесты могут показать наличие 
ошибок в программе, но не могут доказать их отсутствие \autocitate{Dijkstra}.

\subsection{Уровни тестирования ПО}

%TODO: Add image "Levels of testing"

Модульное тестирование (Unit testing)

Интеграционное тестирование (Integration testing)

Приемочное тестирование (Acceptance testing)

%TODO: Add more info about phases of software testing and development  


\subsection{Правила кодирования}

На ряду с тестированием одним из подходов к написанию безопасного и переносимого ПО 
является использование в разработке стандартов кодирования. 

Одним из подобных стандартов является MISRA. Проект MISRA (Motor Industry Software Reliability 
Association) был основан для создания руководства по разработке ПО для микроконтроллеров в 
наземных средствах по заказу правительства Британии. Первое руководство вышло в 1994 году, не 
было привязано к какому-либо языку. Первый связанный с языком С стандрат MISRA C стал 
общепринятым.

В MISRA C правила деляться на три основных категории: Mandatory, Required и Advisory. Mandatory -
наиболее строгая категория, требующая постоянного выполнения. Required - менее строгая: возможны 
отклонения при условии документирования и обоснования. Advisory - правила, которым следовать 
не обязательно.

В MISRA-C:1998 перечислено 127 правил (93 обязательных и 34 рекомендательных).

В MISRA-C:2004 141 правило (121 обязательное и 20 рекомендательных). Правила разделены на 21 категорию.

В MISRA-C:2012 143 правила (каждое из которых может быть проверено статическим анализатором кода) и 16 директив 
(правил, соответствие которым открыто для интерпретаций или связано с процессами и процедурами). Правила делятся 
на обязательные, требуемые и рекомендательные; могут распространяться на отдельные единицы трансляции или на всю 
систему.

В MISRA C++ 

\subsection{Первое поколение статических анализаторов. Lint}

Первый инструмент статического анализа Lint появился в конце 1970-x. Впервые разработчики 
получили возможность автоматизировать обнаружение дефектов программного обеспечения на самых 
ранних этапах жизненного цикла приложения, когда их легче всего исправить. Кроме того, это 
давало разработчикам уверенность в качестве своего кода перед релизом. Технология, лежащая в 
основе Lint, была революционной, она использовала компиляторы для проверки дефектов. 

Однако Lint не разработатывался с целью выявления дефектов, вызывающих проблемы во 
время выполнения программы. Скорее, его цель заключалась в том, чтобы выделить подозрительные 
или непереносимые конструкции в коде и помочь разработчикам соблюдать общий формат при 
кодировании. Под "подозрительным кодом" имееся в виду код, который, будучи технически правильным 
с точки зрения языка исходного кода (например C, С++), может быть структурирован так, чтобы он 
выполнялся способами, которые разработчик не предполагал. Lint являлся дополнением к компилятору. В то время как  компилятор концетрировался на быстром и точном превращении программы в послдовательность бит, Lint концетрировался на ошибках в переносимости, стиле и эффективности.
Из-за ограниченных возможностей анализа Lint, уровень шума был чрезвычайно высоким, часто превышая соотношение между шумом и реальными дефектами в соотношении 10 к 1.

Следовательно, обнаружение настоящих дефектов требовало от разработчиков проведения трудоемкой 
ручной проверки результатов Lint, что усложняло именно ту проблему, которую должен был 
устранить статический анализ. По этой причине Lint так и не получил широкого распространения в 
качестве инструмента обнаружения дефектов, хотя имел ограниченный успех в нескольких 
организациях. Фактически, как свидетельство качества технологии, лежащей в основе Lint, 
множество различных версий продукта по-прежнему доступны сегодня. %TODO: Add links to products

\subsection{Второе поколение статических анализаторов}

Почти два десятилетия статический анализ оставался скорее фикцией, чем коммерчески 
жизнеспособным производственным инструментом для выявления дефектов. В начале 2000 года
появилось второе поколение инструментов (Stanford Checker). Используя новые 
технологии, оно расширяло возможности инструментов первого поколения от простого выявления 
нежелательных паттернов до покрытия путей выполнения. Эти инструменты могли анализировать 
целые базы кода, а не только один файл. 

Сместив фокус с "подозрительных конструкций" на "дефекты времени выполнения", разработчики 
статического анализа осознали необходимость в большем понимания внутреннего 
устройста программ. Это означало объединение сложного анализа путей с межпроцедурным анализом, 
чтобы понять, что происходит, когда поток управления переходит от одной функции к другой в 
рамках данной программы.

Несмотря на принятие и использование организациями, статический анализ 2-го поколения все еще 
не мог найти золотую середину между точностью и масштабируемостью. Некоторые решения были 
точными для небольшого набора типов дефектов, но не могли масштабироваться для анализа 
миллионов строк кода. Другие могли работать за короткое время, но имели показатели точности, 
аналогичные Lint, представляя похожие проблемы с ложными срабатываниеми и шумом. После 
внедрения в процесс разработки эти инструменты могут сообщать о дефектах в приемлемом 
соотношении, но только с ограниченными параметрами анализа. 

Инструментам второго поколения требовались однородные среды сборки и разработки. 
Из-за этого внедрить их в какой то проект было сложной задачей, требовавшей больших усилий.

Борьба между точностью и маштабируемостью вылилась в проблему с ложными срабатываниями. Подобно 
шуму, от которого страдали инструменты первого поколения, ложные срабатывания тормозили 
распространению инструментов нового поколения. 

\subsection{Третье поколение статических анализаторов}
%TODO: add date of birth for 3rd generation
Третье поколение инструментов статической проверки программ превосходит своих предшественников по
всем параметрам и является неотъемлемой частью процессов и сред разработки.  

\FloatBarrier
