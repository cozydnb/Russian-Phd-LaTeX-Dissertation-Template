\chapter{Обзор}\label{ch:ch1}

\section{История автоматического анализа программ}\label{sec:ch1/sec1}
% Ранняя история верификации программ
%TODO: add references
В 1947 году появились термины «ошибка» (bug) и «отладка» (debugging). Грейс Мюррей, 
ученая из Гарвардского университета, работавшая с компьютером Mark II, обнаружила, 
что мотылек застрял в реле, из-за чего оно не вступало в контакт. Она подробно 
описала инцидент в рабочем журнале, приклеив мотылька лентой в качестве доказательства и 
назвав мотылька «ошибкой», вызывающей ошибку, а действие по устранению ошибки - «отладкой».
%TODO: reformulate bug

В то время тесты были сосредоточены на оборудовании, потому что оно было не так развито, как 
сегодня, и его надежность была важна для правильного функционирования программного обеспечения.
Термин отладка был связан с применением исправлений для конкретной ошибки как одна из фаз в 
стадии разработки программного обеспечения. Проводимые тесты имели коррекционный характер и 
выполнялись для устранения ошибок, не дававших программе работать. 

В 1957 году Чарльз Бейкер объясняет необходимость разработки тестов, чтобы гарантировать, что 
программное обеспечение соответствует заранее разработанным требованиям (тестирование), а также 
функциональным возможностям программы (отладка). Разработка тестов стала более важной по мере 
того, как разрабатывались более дорогие и сложные приложения, и стоимость устранения всех этих 
недостатков оказывала явный риск для прибыльности проекта. Особое внимание было уделено 
увеличению количества и качества тестов, и впервые качество продукта стало связано с фазой 
тестирования. Цель заключалась в том, чтобы продемонстрировать, что программа выполняет то, что 
от нее требовалось, с использованием ожидаемых и выдаваемых параметров.

В 1979 году Гленфорд Дж. Майерс радикально меняет процедуру обнаружения ошибок в программе:
"Тестирование программного обеспечения - это процесс запуска программы с целью поиска ошибок."
Обеспокоенность Майерса заключалась в том, что, преследуя цель продемонстрировать, что программа 
безупречна, можно подсознательно выбрать тестовые данные, которые имеют низкую вероятность 
вызвать сбои программы, тогда как если цель состоит в том, чтобы продемонстрировать, что 
программа ошибочна, тестовые данные будут имеют большую вероятность их обнаружения, и мы будем 
более успешными в тестировании и, следовательно, в качестве программного обеспечения. C этого
момента тесты будут пытаться продемонстрировать, что программа не работает должным образом, в 
отличие от того, как это делалось ранее, что приведет к новым методам тестирования и анализа.

В 1983 году была предложена методология, которая объединяет действия по анализу, пересмотру 
(revision) и тестированию в течение жизненного цикла программного обеспечения, чтобы получить 
оценку продукта в процессе разработки. Этап тестирования признан неотъемлемым этапом в 
разработке продукта, приобретая особое значение в связи с появлением инструментов для разработки 
автоматизированных тестов, которые заметно повысили эффективность.

В 1988 году Уильям Хетцель опубликовал «Рост тестирования программного обеспечения», в котором 
он переопределил концепцию тестирования как планирование, проектирование, создание, обслуживание 
и выполнение тестов и тестовых сред. Это  в основном отразилось на появлении фазы тестирования 
на самом раннем этапе разработки продукта, этапе планирования. Если мы представим весь процесс 
разработки в виде конечной линии, где начало - это планирование, а конец - мониторинг проданного 
продукта, мы увидим, как фаза тестирования переместилась влево. Онa появилась как этап пост-
продакшнен, позже это был этап предпродакшн, а сейчас она находится на стадии завершения. Эта 
практика известна как Shift-Left.

Э. В. Дейкстра в лекции «О надёжности программ» утверждает, что тесты могут показать наличие 
ошибок в программе, но не могут доказать их отсутствие\autocite{Dijkstra}. Таким образом 
использование одного тестирования в процессе верификации программы не является достаточным. 

\subsection{Уровни тестирования ПО}
Процесс тестирования представляет из себя несколько уровней. 

Модульное тестирование (Unit testing) - это процесс тестирования отдельных подпрограмм, или 
процедур в программе. Прежде чем тестировать всю программу целиком следует сконцентрироваться 
на отдельных ее частях. Это объясняется рядом причин. Во первых, модульное тестирование облегчает задачу
отладки(процесс выявления и исправления обнаруженной ошибки), так как, когда ошибка найдена 
область ее распространения ограничена размерами модуля. Во вторых, это позволяет распараллелить 
процесс тестирования проверяя сразу несколько модулей одновременно. Целью модульного тестирования
является сравнение значения функции модуля некоторой функции или интерфейсу спецификации, 
определенной модулем. Следует подчеркнуть, что цель, как и для любого процесса тестирования, в том
чтобы найти несоответствие спецификации. 

Когда заканчивается модульное тестирование программы, в действительности процесс тестирования 
только начинается. Особенно это касается больших или сложных программ. Программная ошибка возникает, когда программа не выполняет то, что ее конечный пользователь обоснованно ожидает от 
нее. Согласно данному определения, даже проведя абсолютно идеальный модульный тест нельзя 
утверждать, что все ошибки найдены. Таким образом, для завершения тестирования необходимо какое-
то дополнительное тестирование. В\autocite{artoftesting} это называется тестированием высшего 
порядка.

Разработка программного обеспечения - это в значительной степени процесс передачи информации о 
реализуемой программе и перевода этой информации из одной формы в другую. По этой причине 
подавляющее большинство ошибок программного обеспечения можно отнести к сбоям, ошибкам и 
помехам во время передачи и перевода информации.

Ход процесса разработки ПО можно описать семью шагами:

1. Требования пользователя программы переводятся в набор письменных требований. Это цели продукта.
2. Требования преобразуются в конкретные цели путем оценки осуществимости и стоимости, разрешения противоречивых требований и установления приоритетов и компромиссов.
3. Цели переводятся в точную спецификацию продукта, в которой продукт рассматривается как черный ящик и учитываются только его интерфейсы и взаимодействие с конечным пользователем. Это описание называется внешней спецификацией.
4. Если продукт представляет собой систему, такую как операционная система, система управления полетом, система управления базами данных или кадровая система сотрудников, а не программа (компилятор, программа расчета заработной платы, текстовый процессор), следующим процессом является проектирование системы. На этом этапе система разделяется на отдельные программы, компоненты или подсистемы и определяется их интерфейсы.
5. Структура программы или программ разрабатывается путем определения функции каждого модуля, иерархической структуры модулей и интерфейсов между модулями.
6. Разработана точная спецификация, определяющая интерфейс и функции каждого модуля.
7. Через один или несколько подшагов спецификация интерфейса модуля транслируется в алгоритм исходного кода каждого модуля.

Учитывая предпосылку, что семь этапов цикла разработки включают в себя общение, понимание и 
перевод информации, а также предпосылку, что большинство ошибок программного обеспечения 
происходит из-за сбоев в обработке информации, существует три дополнительных подхода для 
предотвращения и/или обнаружения этих ошибок. Во-первых, мы можем внести больше точности в 
процесс разработки, чтобы предотвратить многие ошибки. Во-вторых, мы можем ввести в конце 
каждого процесса отдельный этап проверки, чтобы определить как можно больше ошибок, прежде чем 
переходить к следующему процессу. Третий подход - ориентировать отдельные процессы 
тестирования на отдельные процессы разработки. То есть сосредоточить каждый процесс 
тестирования на конкретном этапе перевода, таким образом фокусируя его на определенном классе ошибок. %TODO: Add image.
Другими словами, вы должны иметь возможность установить взаимно однозначное соответствие между процессами разработки и тестирования.

Функциональное тестирование (Functional testing) - это попытка найти расхождения между 
программой и внешней спецификацией. Внешняя спецификация - это точное описание поведения 
программы с точки зрения конечного пользователя. За исключением случаев использования в 
небольших программах, функциональное тестирование обычно представляет собой черный ящик.
Чтобы выполнить функциональный тест, спецификация анализируется для получения набора тестовых 
примеров.

Системное тестирование (System testing) - это самый непонятый и самый сложный из процессов 
тестирования. Системное тестирование - это не процесс тестирования функций всей системы или 
программы, потому что это будет дублировать процесс функционального тестирования. Системное 
тестирование имеет конкретную цель: сравнить систему или программу с ее первоначальными 
целями.

Приемочное тестирование (Acceptance testing) - это процесс сравнения программы с исходными требованиями 
и текущими потребностями конечных пользователей. Это необычный тип тестирования, поскольку он обычно 
выполняется заказчиком программы или конечным пользователем и обычно не считается обязанностью 
организации-разработчика.

На ряду с тестированием одним из подходов к написанию безопасного и переносимого ПО 
является использование в разработке стандартов кодирования. 

\subsection{Правила кодирования}

Спустя полвека с момента своего создания язык программирования C по-прежнему остается одним из наиболее часто 
используемых языков программирования\autocite{TiobeIndex} и наиболее часто используемый для разработки 
встраиваемых систем. Причины такого успеха уходят корнями в требования отрасли. Среди таких требований - размер 
языка, стабильность и путь развития, обеспечивающий обратную совместимость.

Характеристики, которые сделали язык программирования C таким успешным, имеют недостатки: написание безопасных 
и защищенных приложений на C требует особой осторожности. В противном случае код может получиться 
запутанным и неясным. Замечательные примеры подобных программ представлены на международном конкурсе 
запутанного С кода \autocite{ioccc}. Решение, обязательное или настоятельно рекомендуемое 
всеми применимыми промышленными стандартами - language subsetting: критически важные приложения не 
программируются на неограниченном языке C, а программируются в подмножестве, где вероятность совершения 
потенциально опасных ошибок снижена. Это требуется или настоятельно рекомендуется всеми стандартами 
безопасности, таким как, например, IEC 61508\autocite{IEC61508}.

Конечно, кодирования на более безопасном подмножестве C недостаточно для гарантии корректности. Однако:

\begin{itemize}
    \item Ограничение языкового подмножества, в котором не полностью определенное поведение и 
    проблемные функции запрещены или строго регулируются, «может значительно повысить эффективность и  
    точность статического анализа»\autocite{astreeConf};
    \item Правильно спроектированные языковые подмножества имеют сильное влияние на читаемость кода:
    ревью кода в сочетании со статическим анализом и соблюдением правил кодирования являются основой 
    наиболее эффективных стратегий устранения дефектов.  
\end{itemize}

Согласно\autocite{bagnara2020barrc2018} в опросе среди специалистов встроенных систем ПО  стандарт кодирования MISRA C\autocite{Misrac1998} - наиболее широко 
используемый и стандарт BARR-C\autocite{barrc} - второй наиболее используемый. Вместе они получили 40 процентов голосов респондентов.  

Проект MISRA (Motor Industry Software Reliability Association) был основан для создания руководства по разработке ПО для микроконтроллеров в 
наземных средствах по заказу правительства Британии. Работа над проектом началась в 1990 году.  Первое руководство вышло в 1994 году, не 
было привязано к какому-либо языку. Консорциум MISRA приступил к работе на стандартом для языка C: в это же время Форд и Ленд Ровер независимо разрабатывали проприетарные 
руководства для программного обеспечения на языке C для транспортных средств, и было признано, что совместная 
деятельность будет более выгодной для промышленности. Первый связанный с языком С стандарт MISRA C\autocite{Misrac1998} вышел в 1998 году и стал общепринятым. 

В 2004 году MISRA опубликовало улучшенную версию стандарта\autocite{Misrac2004}, расширив целевую аудиторию, 
чтобы включить все отрасли, которые разрабатывают программное обеспечение на C для использования в 
высоконадежных/критических системах. Благодаря успеху MISRA C и тому факту, что C++ также используется в 
критических контекстах, в 2008 г. MISRA опубликовала аналогичный набор рекомендаций MISRA C++
\autocite{Misrac2008}.

И MISRA C:1998, и MISRA C:2004 нацелены на версию стандарта C 1990 г.\autocite{ISOIEC99899in1990}. Последняя 
версия MISRA C:2012, опубликованная в 2013 г.\autocite{Misrac2012} поддерживает оба стандарта: С90 и 
С99\autocite{ISOIEC99899in1999}. По сравнению с предыдущими версиями, MISRA C:2012 охватывает больше языковых 
проблем и предоставляет более точную спецификацию с улучшенными обоснованием и примерами.

MISRA C повлиял на все общедоступные стандарты кодирования для C и C++, которые были разработаны после MISRA 
C:1998. MISRA C:1998 повлиял на JSF Air Vehicle C++ Coding Standards\autocite{JSF}, который в свою очередь повлиял на MISRA C++:2008.

В MISRA C правила делятся на три основных категории: Mandatory, Required и Advisory. Mandatory -
наиболее строгая категория, требующая постоянного выполнения. Required - менее строгая: возможны 
отклонения при условии документирования и обоснования. Advisory - правила, которым следовать 
не обязательно.

В MISRA-C:1998 перечислено 127 правил (93 обязательных и 34 рекомендательных).

В MISRA-C:2004 141 правило (121 обязательное и 20 рекомендательных). Правила разделены на 21 категорию.

В MISRA-C:2012 143 правила (каждое из которых может быть проверено статическим анализатором кода) и 16 директив 
(правил, соответствие которым открыто для интерпретаций или связано с процессами и процедурами). Правила делятся 
на обязательные, требуемые и рекомендательные; могут распространяться на отдельные единицы трансляции или на всю 
систему.

На стандарт BARR:2018 оказали влияние MISRA C:2012, BARR C:2013 и NETRINO EMBEDDED C. Как следствие BARR:2018 является 
надмножеством MISRA C:2012 и может использоваться, как плавный первый шаг для проекта без статического анализа и правил кодирования 
к проекту, соответствующему MISRA C:2012.

Другими примерами стандарта кодирования для обеспечения безопасности критических систем являются:
\begin{itemize}
    \item "JPL Institutional Coding Standard for the C Programming Language"\autocite{JPL} от НАСА. Данный стандарт испытал влияние MISRA C:2004 и 
        стандарта "Сила десяти"\autocite{powerOfTen}. Ни один из этих двух данных источников не рассматривает программные риски, связанные с использованием 
        многопоточного программного обеспечения. Этот стандарт призван заполнить этот пробел.
    \item "High Integrity C++"\autocite{highIntegrity} от Programming Research Ltd. 
    \item "JOINT STRIKE FIGHTER AIR VEHICLE C++ CODING STANDARDS"\autocite{JSF} от Lockheed.
    \item "Embedded System development Coding Reference guide for C/C++"\autocite{escrC, escrCPP} от Information-technology Promotion Agency, Japan.
    \item "Guidelines for the use of the C++14 language in critical and safety-related systems"\autocite{autosar} от AUTOSAR.
    \item "The SEI CERT C/C++ Coding Standart" от Carnegie Mellon University\autocite{CERT}. 
\end{itemize}

\subsection{Бенчмарки для проверки статических анализаторов}
Бенчмаркинг обеспечивает объективный и повторяемый способ измерения свойств инструмента обнаружения ошибок. Бенчмарки для инструментов обнаружения 
ошибок должен отвечать на несколько вопросов о результатах работы инструмента\autocite{}: 
- Сколько ошибок обнаружены правильно?
- Сколько ложных сообщений об ошибках сделано?
- Сколько ошибок пропущено/не сообщается?
- Насколько хорошо масштабируется инструмент?

Не на все эти вопросы можно ответить с помощью одного тестового набора. Чтобы измерить масштабируемость инструмента, необходимы большие распределения 
кода с миллионами строк кода, которые будут репрезентативными для реального мира. Однако определение того, сколько ошибок сообщается правильно и 
неправильно или сколько ошибок пропущено, является невозможно для больших баз кода из-за практических ограничения на обнаружение всех ошибок в большой 
программе. Таким образом выделяются два основных типа бенчмарков. 

Маленькие бенчмарки размером от 10 до тысячи строк кода состоят из синтетических тестов, либо из автономных программы, извлеченные из существующего 
ошибочного кода, которые содержат конкретную ошибку. В работе\autocite{Zitser} извлечено 15 багов из реальных приложений. В работе\autocite{Kratkiewicz} синтезировано 
291 тесткейса ошибки переполнения буфера. Один из наиболее известных для данных целей тестовый набор - Juliet Test Suite\autocite{NIST}. Juliet Test Suite был разработан Центр гарантированного 
программного обеспечения (Center for Assured Software) Агентства национальной безопасности США (US American National Security Agency).
Его тестовые сценарии были созданы для тестирования сканеров или другого программного обеспечения. Набор тестов состоит из двух частей. Одна часть 
посвящена ошибкам безопасности для языков программирования C и C++. Другой касается ошибок безопасности для языка Java. Примеры кода с уязвимостями 
безопасности даны в простой форме, а также встроены в вариации различных потоков управления и паттернов потоков данных. Пакет содержит около 57 000 
тестовых случаев на C/C++ и около 24000 тестовых случаев на Java. Набор тестов охватывает 25 основных ошибок безопасности, определенных SANS/MITRE 
(MITRE 2011)\autocite{MITRE}. Можно выделить два типа исходного кода: искусственный код и естественный код. Естественный код используется в реальном программном обеспечении, таком 
как, например, веб-сервер Apache или Microsoft Word. Искусственный код создается для определенной цели, например, для тестирования сканеров 
безопасности. Juliet Test Suite содержит только искусственный код, поскольку такой код упрощает оценку и сравнение инструментов статического анализа. 

Примерами больших бенчмарков в виде полных программных дистрибутивов являются BugBench\autocite{BugBench} и Faultbench\autocite{Faultbench}.

Данные бенчмарки не являются общими, переносными или многоразовыми; все ключевые свойства, позволяющие сделать набор тестов полезным.  
BegBunch\autocite{BegBunch} устраняет эти недостатки, предоставляя два набора для оценки качественной и количественной производительности инструментов 
обнаружения ошибок, а также автоматизирует запуск  инструмента обнаружения ошибок, проверку результатов и составления отчетов о данных производительности. 

\subsection{Первое поколение статических анализаторов. Lint}

Первый инструмент статического анализа Lint появился в конце 1970-x. Впервые разработчики 
получили возможность автоматизировать обнаружение дефектов программного обеспечения на самых 
ранних этапах жизненного цикла приложения, когда их легче всего исправить. Кроме того, это 
давало разработчикам уверенность в качестве своего кода перед релизом. Технология, лежащая в 
основе Lint, была революционной, она использовала компиляторы для проверки дефектов. 

Однако Lint не разрабатывался с целью выявления дефектов, вызывающих проблемы во 
время выполнения программы. Скорее, его цель заключалась в том, чтобы выделить подозрительные 
или непереносимые конструкции в коде и помочь разработчикам соблюдать общий формат при 
кодировании. Под "подозрительным кодом" имеется в виду код, который, будучи технически правильным 
с точки зрения языка исходного кода (например C, С++), может быть структурирован так, чтобы он 
выполнялся способами, которые разработчик не предполагал. Lint являлся дополнением к компилятору. В то время как  компилятор концентрировался на быстром и точном превращении программы в последовательность бит, Lint концентрировался на ошибках в переносимости, стиле и эффективности.
Из-за ограниченных возможностей анализа Lint, уровень шума был чрезвычайно высоким, часто превышая соотношение между шумом и реальными дефектами в соотношении 10 к 1.

Следовательно, обнаружение настоящих дефектов требовало от разработчиков проведения трудоемкой 
ручной проверки результатов Lint, что усложняло именно ту проблему, которую должен был 
устранить статический анализ. По этой причине Lint так и не получил широкого распространения в 
качестве инструмента обнаружения дефектов, хотя имел ограниченный успех в нескольких 
организациях. Фактически, как свидетельство качества технологии, лежащей в основе Lint, 
множество различных версий продукта по-прежнему доступны сегодня. %TODO: Add links to products

\subsection{Второе поколение статических анализаторов}
Почти два десятилетия статический анализ оставался скорее фикцией, чем коммерчески 
жизнеспособным производственным инструментом для выявления дефектов. В начале 2000 года
появилось второе поколение инструментов (Stanford Checker). Используя новые 
технологии, оно расширяло возможности инструментов первого поколения от простого выявления 
нежелательных паттернов до покрытия путей выполнения. Эти инструменты могли анализировать 
целые базы кода, а не только один файл. 

Сместив фокус с "подозрительных конструкций" на "дефекты времени выполнения", разработчики 
статического анализа осознали необходимость в большем понимания внутреннего 
устройстава программ. Это означало объединение сложного анализа путей с межпроцедурным анализом, 
чтобы понять, что происходит, когда поток управления переходит от одной функции к другой в 
рамках данной программы.

Несмотря на принятие и использование организациями, статический анализ 2-го поколения все еще 
не мог найти золотую середину между точностью и масштабируемостью. Некоторые решения были 
точными для небольшого набора типов дефектов, но не могли масштабироваться для анализа 
миллионов строк кода. Другие могли работать за короткое время, но имели показатели точности, 
аналогичные Lint, представляя похожие проблемы с ложными срабатываниями и шумом. После 
внедрения в процесс разработки эти инструменты могут сообщать о дефектах в приемлемом 
соотношении, но только с ограниченными параметрами анализа. 

Инструментам второго поколения требовались однородные среды сборки и разработки. 
Из-за этого внедрить их в какой то проект было сложной задачей, требовавшей больших усилий.

Борьба между точностью и маcштабируемостью вылилась в проблему с ложными срабатываниями. Подобно 
шуму, от которого страдали инструменты первого поколения, ложные срабатывания тормозили 
распространению инструментов нового поколения. 

\subsection{Третье поколение статических анализаторов}
%TODO: add date of birth for 3rd generation
Третье поколение инструментов статической проверки программ превосходит своих предшественников по
всем параметрам и является неотъемлемой частью процессов и сред разработки.  

\subsection{}


\FloatBarrier
