\chapter{Обзор}\label{ch:ch1}
Надежность - главная проблема современных процессов разработки программного обеспечения. Поскольку сложность системы постоянно растет, традиционные 
методы тестирования не справляются с задачей проверки. Разработка программного обеспечения, даже для встраиваемых систем, стала глобальной задачей, в 
которую вовлечены разработчики из различных филиалов. Географически разделенные инженеры создают тысячи или даже миллионы строк кода и, возможно, 
никогда не видели друг друга. Контроль качества процессов производства современного программного обеспечения стал значительно труднее. С другой стороны, 
неисправность программного обеспечения обходится дорого с точки зрения сбоя самого приложения, но также из-за вытекающих из этого последствий, таких как 
несчастные случаи со смертельным исходом, потеря денег, отключение жизненно важных систем, потеря репутации и выплаты.

Убедиться в тезисе, представленном выше, можно на примере следующих известных сбоев программного обеспечения:

\textbf{Взрыв пусковой установки "Ариан 5" (1996 г.).} Первый полет ракеты-носителя "Ариан-5" в июне 1996 года потерпел неудачу из-за сбоя в управляющем 
программном обеспечении. Необработанное исключение привело к самоуничтожению ракеты всего через 37 секунд после запуска. Неудачное преобразование 
данных из 64-битного числа с плавающей запятой в 16-битное целое число со знаком является одной из самых дорогих программных ошибок в аэрокосмической отрасли\cite{Lions1996ARIANE5F}.

\textbf{Утрата орбитального аппарата NASA Mars Climate Orbiter (1999 г.).} ... % TODO 

\section{История автоматического анализа программ}\label{sec:ch1/sec1}
% Ранняя история верификации программ
%TODO: add references
В 1947 году появились термины «ошибка» (bug) и «отладка» (debugging). Грейс Мюррей, 
ученая из Гарвардского университета, работавшая с компьютером Mark II, обнаружила, 
что мотылек застрял в реле, из-за чего оно не вступало в контакт. Она подробно 
описала инцидент в рабочем журнале, приклеив мотылька лентой в качестве доказательства и 
назвав мотылька «ошибкой», вызывающей ошибку, а действие по устранению ошибки - «отладкой».
%TODO: reformulate bug

В то время тесты были сосредоточены на оборудовании, потому что оно было не так развито, как 
сегодня, и его надежность была важна для правильного функционирования программного обеспечения.
Термин отладка был связан с применением исправлений для конкретной ошибки как одна из фаз в 
стадии разработки программного обеспечения. Проводимые тесты имели коррекционный характер и 
выполнялись для устранения ошибок, не дававших программе работать. 

В 1957 году Чарльз Бейкер объясняет необходимость разработки тестов, чтобы гарантировать, что 
программное обеспечение соответствует заранее разработанным требованиям (тестирование), а также 
функциональным возможностям программы (отладка)\cite{Baker}. Разработка тестов стала более важной по мере 
того, как разрабатывались более дорогие и сложные приложения, и стоимость устранения всех этих 
недостатков оказывала явный риск для прибыльности проекта. Особое внимание было уделено 
увеличению количества и качества тестов, и впервые качество продукта стало связано с фазой 
тестирования. Цель заключалась в том, чтобы продемонстрировать, что программа выполняет то, что 
от нее требовалось, с использованием ожидаемых и выдаваемых параметров.

В 1979 году Гленфорд Дж. Майерс радикально меняет процедуру обнаружения ошибок в программе:
"Тестирование программного обеспечения - это процесс запуска программы с целью поиска ошибок."\cite{Myers1979}
Обеспокоенность Майерса заключалась в том, что, преследуя цель продемонстрировать, что программа 
безупречна, можно подсознательно выбрать тестовые данные, которые имеют низкую вероятность 
вызвать сбои программы, тогда как если цель состоит в том, чтобы продемонстрировать, что 
программа ошибочна, тестовые данные будут имеют большую вероятность их обнаружения, и мы будем 
более успешными в тестировании и, следовательно, в качестве программного обеспечения. C этого
момента тесты будут пытаться продемонстрировать, что программа не работает должным образом, в 
отличие от того, как это делалось ранее, что приведет к новым методам тестирования и анализа.

В 1983 году была предложена методология, которая объединяет действия по анализу, пересмотру 
(revision) и тестированию в течение жизненного цикла программного обеспечения, чтобы получить 
оценку продукта в процессе разработки. Этап тестирования признан неотъемлемым этапом в 
разработке продукта, приобретая особое значение в связи с появлением инструментов для разработки 
автоматизированных тестов, которые заметно повысили эффективность.

В 1988 году Уильям Хетцель опубликовал «Рост тестирования программного обеспечения»\cite{Hetzel}, в котором 
он переопределил концепцию тестирования как планирование, проектирование, создание, обслуживание 
и выполнение тестов и тестовых сред. Это  в основном отразилось на появлении фазы тестирования 
на самом раннем этапе разработки продукта, этапе планирования. Если мы представим весь процесс 
разработки в виде конечной линии, где начало - это планирование, а конец - мониторинг проданного 
продукта, мы увидим, как фаза тестирования переместилась влево. Онa появилась как этап пост-
продакшнен, позже это был этап предпродакшн, а сейчас она находится на стадии завершения. Эта 
практика известна как Shift-Left.

Э. В. Дейкстра в лекции «О надёжности программ» утверждает, что тесты могут показать наличие 
ошибок в программе, но не могут доказать их отсутствие\cite{Dijkstra}. Таким образом 
использование одного тестирования в процессе верификации программы не является достаточным. 

\subsection{Уровни тестирования ПО}
Процесс тестирования представляет из себя несколько уровней. 

Модульное тестирование (Unit testing) - это процесс тестирования отдельных подпрограмм, или 
процедур в программе. Прежде чем тестировать всю программу целиком следует сконцентрироваться 
на отдельных ее частях. Это объясняется рядом причин. Во-первых, модульное тестирование облегчает задачу
отладки(процесс выявления и исправления обнаруженной ошибки), так как, когда ошибка найдена 
область ее распространения ограничена размерами модуля. Во-вторых, это позволяет распараллелить 
процесс тестирования проверяя сразу несколько модулей одновременно. Целью модульного тестирования
является сравнение значения функции модуля некоторой функции или интерфейсу спецификации, 
определенной модулем. Следует подчеркнуть, что цель, как и для любого процесса тестирования, в том
чтобы найти несоответствие спецификации. 

Когда заканчивается модульное тестирование программы, в действительности процесс тестирования 
только начинается. Особенно это касается больших или сложных программ. Программная ошибка возникает, когда программа не выполняет то, что ее конечный пользователь обоснованно ожидает от 
нее. Согласно данному определения, даже проведя абсолютно идеальный модульный тест нельзя 
утверждать, что все ошибки найдены. Таким образом, для завершения тестирования необходимо какое-то 
дополнительное тестирование. В\cite{Myers2004} это называется тестированием высшего порядка.

Разработка программного обеспечения - это в значительной степени процесс передачи информации о 
реализуемой программе и перевода этой информации из одной формы в другую. По этой причине 
подавляющее большинство ошибок программного обеспечения можно отнести к сбоям, ошибкам и 
помехам во время передачи и перевода информации.

Ход процесса разработки ПО можно описать семью шагами:

1. Требования пользователя программы переводятся в набор письменных требований. Это цели продукта.
2. Требования преобразуются в конкретные цели путем оценки осуществимости и стоимости, разрешения противоречивых требований и установления приоритетов и компромиссов.
3. Цели переводятся в точную спецификацию продукта, в которой продукт рассматривается как черный ящик и учитываются только его интерфейсы и взаимодействие с конечным пользователем. Это описание называется внешней спецификацией.
4. Если продукт представляет собой систему, такую как операционная система, система управления полетом, система управления базами данных или кадровая система сотрудников, а не программа (компилятор, программа расчета заработной платы, текстовый процессор), следующим процессом является проектирование системы. На этом этапе система разделяется на отдельные программы, компоненты или подсистемы и определяется их интерфейсы.
5. Структура программы или программ разрабатывается путем определения функции каждого модуля, иерархической структуры модулей и интерфейсов между модулями.
6. Разработана точная спецификация, определяющая интерфейс и функции каждого модуля.
7. Через один или несколько подшагов спецификация интерфейса модуля транслируется в алгоритм исходного кода каждого модуля.

Учитывая предпосылку, что семь этапов цикла разработки включают в себя общение, понимание и 
перевод информации, а также предпосылку, что большинство ошибок программного обеспечения 
происходит из-за сбоев в обработке информации, существует три дополнительных подхода для 
предотвращения и/или обнаружения этих ошибок. Во-первых, мы можем внести больше точности в 
процесс разработки, чтобы предотвратить многие ошибки. Во-вторых, мы можем ввести в конце 
каждого процесса отдельный этап проверки, чтобы определить как можно больше ошибок, прежде чем 
переходить к следующему процессу. Третий подход - ориентировать отдельные процессы 
тестирования на отдельные процессы разработки. То есть сосредоточить каждый процесс 
тестирования на конкретном этапе перевода, таким образом фокусируя его на определенном классе ошибок. %TODO: Add image.
Другими словами, вы должны иметь возможность установить взаимно однозначное соответствие между процессами разработки и тестирования.

Функциональное тестирование (Functional testing) - это попытка найти расхождения между 
программой и внешней спецификацией. Внешняя спецификация - это точное описание поведения 
программы с точки зрения конечного пользователя. За исключением случаев использования в 
небольших программах, функциональное тестирование обычно представляет собой черный ящик.
Чтобы выполнить функциональный тест, спецификация анализируется для получения набора тестовых 
примеров.

Системное тестирование (System testing) - это финальное тестирование программы с проверкой всех функциональных и 
нефункциональных требований. Системное тестирование - это не процесс тестирования функций всей системы или 
программы, потому что это будет дублировать процесс функционального тестирования. Системное 
тестирование имеет конкретную цель: сравнить систему или программу с ее первоначальными 
целями.

Приемочное тестирование (Acceptance testing) - это процесс сравнения программы с исходными требованиями 
и текущими потребностями конечных пользователей. Это необычный тип тестирования, поскольку он обычно 
выполняется заказчиком программы или конечным пользователем и обычно не считается обязанностью 
организации-разработчика.

На ряду с тестированием одним из подходов к написанию безопасного и переносимого ПО 
является использование в разработке стандартов кодирования. 

\subsection{Правила кодирования}

Спустя полвека с момента своего создания язык программирования C по-прежнему остается одним из наиболее часто 
используемых языков программирования\cite{TiobeIndex} и наиболее часто используемый для разработки 
встраиваемых систем. Причины такого успеха уходят корнями в требования отрасли. К подобным причинам относятся\cite{bagnara2018misra}:
\begin{itemize}
    \item Компиляторы C существуют практически для любого процессора, от крошечных DSP, используемых в слуховых аппаратах, до суперкомпьютеров.
    \item Скомпилированный код на C может быть очень эффективным и без скрытых затрат, т.е. программисты могут приблизительно предсказать время 
        выполнения еще до тестирования и до использования инструментов для наихудшего приближения времени выполнения (Это по-прежнему верно для 
        реализаций, работающих на простых процессорах, с ограниченной степенью кэширования и внутреннего параллелизма. Предсказание максимального 
        времени работы без инструментов становится совершенно невозможным для современных многоядерных систем, таких как Kalray MPPA, Freescale P4080 
        или эквиваленты ARM Cortex-A57).
    \item C позволяет писать компактный код.
    \item C определяется международными стандартами: он был впервые стандартизирован в 1989 году Американским национальным институтом стандартов (эта 
        версия языка известна как ANSI C), а затем Международной организацией по стандартизации (ISO).
    \item C, возможно с расширениями, обеспечивает легкий доступ к аппаратному оборудованию, что является необходимым для разработки встроенного 
        программного обеспечения.
    \item C имеет долгую историю использования во всех типах систем, включая системы безопасности, защиты, критически важные для бизнеса.
    \item C широко поддерживается всевозможными инструментами.
\end{itemize}

На ряду с достоинствами C имеет и недостатки: написание безопасных 
и защищенных приложений на C требует особой осторожности. В противном случае код может получиться 
запутанным и неясным. Замечательные примеры подобных программ представлены на международном конкурсе 
запутанного С кода \cite{ioccc}. Решение, обязательное или настоятельно рекомендуемое 
всеми применимыми промышленными стандартами - language subsetting: критически важные приложения не 
программируются на неограниченном языке C, а программируются в подмножестве, где вероятность совершения 
потенциально опасных ошибок снижена. Это требуется или настоятельно рекомендуется всеми стандартами 
безопасности, таким как, например, IEC 61508\cite{IEC61508}.

Конечно, кодирования на более безопасном подмножестве C недостаточно для гарантии корректности. Однако:

\begin{itemize}
    \item Ограничение языкового подмножества, в котором не полностью определенное поведение и 
    проблемные функции запрещены или строго регулируются, «может значительно повысить эффективность и  
    точность статического анализа»\cite{astreeConf};
    \item Правильно спроектированные языковые подмножества имеют сильное влияние на читаемость кода:
    ревью кода в сочетании со статическим анализом и соблюдением правил кодирования являются основой 
    наиболее эффективных стратегий устранения дефектов.  
\end{itemize}

Согласно\cite{bagnara2020barrc2018} в опросе среди специалистов встроенных систем ПО  стандарт кодирования MISRA C\cite{Misrac1998} - наиболее широко 
используемый и стандарт BARR-C\cite{barrc} - второй наиболее используемый. Вместе они получили 40 процентов голосов респондентов.  

Проект MISRA (Motor Industry Software Reliability Association) был основан для создания руководства по разработке ПО для микроконтроллеров в 
наземных средствах по заказу правительства Британии. Работа над проектом началась в 1990 году.  Первое руководство вышло в 1994 году, не 
было привязано к какому-либо языку. Консорциум MISRA приступил к работе на стандартом для языка C: в это же время Форд и Ленд Ровер независимо разрабатывали проприетарные 
руководства для программного обеспечения на языке C для транспортных средств, и было признано, что совместная 
деятельность будет более выгодной для промышленности. Первый связанный с языком С стандарт MISRA C\cite{Misrac1998} вышел в 1998 году и стал общепринятым. 

В 2004 году MISRA опубликовало улучшенную версию стандарта\cite{Misrac2004}, расширив целевую аудиторию, 
чтобы включить все отрасли, которые разрабатывают программное обеспечение на C для использования в 
высоконадежных/критических системах. Благодаря успеху MISRA C и тому факту, что C++ также используется в 
критических контекстах, в 2008 г. MISRA опубликовала аналогичный набор рекомендаций MISRA C++
\cite{Misrac2008}.

И MISRA C:1998, и MISRA C:2004 нацелены на версию стандарта C 1990 г.\cite{ISOIEC99899in1990}. Последняя 
версия MISRA C:2012, опубликованная в 2013 г.\cite{Misrac2012} поддерживает оба стандарта: С90 и 
С99\cite{ISOIEC99899in1999}. По сравнению с предыдущими версиями, MISRA C:2012 охватывает больше языковых 
проблем и предоставляет более точную спецификацию с улучшенными обоснованием и примерами.

MISRA C повлиял на все общедоступные стандарты кодирования для C и C++, которые были разработаны после MISRA 
C:1998. MISRA C:1998 повлиял на JSF Air Vehicle C++ Coding Standards\cite{JSF}, который в свою очередь повлиял на MISRA C++:2008.

В MISRA C правила делятся на три основных категории: Mandatory, Required и Advisory. Mandatory -
наиболее строгая категория, требующая постоянного выполнения. Required - менее строгая: возможны 
отклонения при условии документирования и обоснования. Advisory - правила, которым следовать 
не обязательно.

В MISRA-C:1998 перечислено 127 правил (93 обязательных и 34 рекомендательных).

В MISRA-C:2004 141 правило (121 обязательное и 20 рекомендательных). Правила разделены на 21 категорию.

В MISRA-C:2012 143 правила (каждое из которых может быть проверено статическим анализатором кода) и 16 директив 
(правил, соответствие которым открыто для интерпретаций или связано с процессами и процедурами). Правила делятся 
на обязательные, требуемые и рекомендательные; могут распространяться на отдельные единицы трансляции или на всю 
систему.

На стандарт BARR:2018 оказали влияние MISRA C:2012, BARR C:2013 и NETRINO EMBEDDED C. Как следствие BARR:2018 является 
надмножеством MISRA C:2012 и может использоваться, как плавный первый шаг для проекта без статического анализа и правил кодирования 
к проекту, соответствующему MISRA C:2012.

Другими примерами стандарта кодирования для обеспечения безопасности критических систем являются:
\begin{itemize}
    \item "JPL Institutional Coding Standard for the C Programming Language"\cite{JPL} от НАСА. Данный стандарт испытал влияние MISRA C:2004 и 
        стандарта "Сила десяти"\cite{powerOfTen}. Ни один из данных источников не рассматривает программные риски, связанные с использованием 
        многопоточного программного обеспечения. Стандарт JPL  призван заполнить этот пробел.
    \item "High Integrity C++"\cite{highIntegrity} от Programming Research Ltd. 
    \item "Joint Strike Figther Air Vehicle C++ Coding Standards"\cite{JSF} от Lockheed.
    \item "Embedded System development Coding Reference guide for C/C++"\cite{escrC, escrCPP} от Information-technology Promotion Agency, Japan.
    \item "Guidelines for the use of the C++14 language in critical and safety-related systems"\cite{autosar} от AUTOSAR.
    \item "The SEI CERT C/C++ Coding Standart" от Carnegie Mellon University\cite{CERT}. 
\end{itemize}

\subsection{Бенчмарки для проверки статических анализаторов}
Бенчмаркинг обеспечивает объективный и повторяемый способ измерения свойств инструмента обнаружения ошибок. Бенчмарки для инструментов обнаружения 
ошибок должены отвечать на несколько вопросов о результатах работы инструмента\cite{BegBunch}: 
\begin{itemize}
    \item Сколько ошибок обнаружены правильно?
    \item Сколько ложных сообщений об ошибках сделано?
    \item Сколько ошибок пропущено/не сообщается?
    \item Насколько хорошо масштабируется инструмент?
\end{itemize}

Выделяются два основных типа бенчмарков. 
Маленькие бенчмарки размером от 10 до тысячи строк кода состоят из синтетических тестов, либо из автономных программ, извлеченные из существующего 
ошибочного кода, которые содержат конкретную ошибку. В работе\cite{Zitser} извлечено 15 багов из реальных приложений. В работе\cite{Kratkiewicz} синтезировано 
291 тесткейса ошибки переполнения буфера. Один из наиболее известных для данных целей тестовый набор - Juliet Test Suite\cite{NIST}. Juliet Test Suite был разработан Центр гарантированного 
программного обеспечения (Center for Assured Software) Агентства национальной безопасности США (US American National Security Agency).
Его тестовые сценарии были созданы для тестирования сканеров или другого программного обеспечения. Набор тестов состоит из двух частей. Одна часть 
посвящена ошибкам безопасности для языков программирования C и C++. Другой касается ошибок безопасности для языка Java. В 2019 вышел набор для C\# и 
есть экспериментальные (ещё не стандартизированные) наборы для других языков. Примеры кода с уязвимостями 
безопасности даны в простой форме, а также встроены в вариации различных потоков управления и паттернов потоков данных. Пакет содержит около 64000 
тестовых случаев на C/C++ и около 28000 тестовых случаев на Java. Набор тестов охватывает 25 основных ошибок безопасности, определенных SANS/MITRE 
(MITRE 2011)\cite{MITRE}. Можно выделить два типа исходного кода: искусственно созданные примеры с целью тестирования определенного свойства 
анализатора и код, полученный из репозиториев программ, в которыx были найдены программные ошибки в процессе тестирования или эксплуатации.
Естественный код используется в реальном программном обеспечении, таком 
как, например, веб-сервер Apache или Microsoft Word. Искусственный код создается для определенной цели, например, для тестирования сканеров 
безопасности. Juliet Test Suite содержит только искусственно созданные примеры кода, поскольку такой код упрощает оценку и сравнение инструментов 
статического анализа. 

Примерами больших бенчмарков в виде полных программных дистрибутивов являются BugBench\cite{BugBench} и Faultbench\cite{Faultbench}.

\subsection{Первое поколение статических анализаторов. Lint}

Первый инструмент статического анализа Lint\cite{Johnson78lint} появился в конце 1970-x. Впервые разработчики 
получили возможность автоматизировать обнаружение дефектов программного обеспечения на самых 
ранних этапах жизненного цикла приложения, когда их легче всего исправить. Кроме того, это 
давало разработчикам уверенность в качестве своего кода перед релизом. Технология, лежащая в 
основе Lint, была революционной, она использовала компиляторы для проверки дефектов. 

Однако Lint не разрабатывался с целью выявления дефектов, вызывающих проблемы во 
время выполнения программы. Скорее, его цель заключалась в том, чтобы выделить подозрительные 
или непереносимые конструкции в коде и помочь разработчикам соблюдать общий формат при 
кодировании. Под "подозрительным кодом" имеется в виду код, который, будучи технически правильным 
с точки зрения языка исходного кода (например C, С++), может быть структурирован так, чтобы он 
выполнялся способами, которые разработчик не предполагал. Lint являлся дополнением к компилятору. В то время как  компилятор концентрировался на быстром и точном превращении программы в последовательность бит, Lint концентрировался на ошибках в переносимости, стиле и эффективности.
Из-за ограниченных возможностей анализа Lint, уровень шума был чрезвычайно высоким, часто превышая соотношение между шумом и реальными дефектами в соотношении 10 к 1.

Следовательно, обнаружение настоящих дефектов требовало от разработчиков проведения трудоемкой 
ручной проверки результатов Lint, что усложняло именно ту проблему, которую должен был 
устранить статический анализ. По этой причине Lint так и не получил широкого распространения в 
качестве инструмента обнаружения дефектов, хотя имел ограниченный успех в нескольких 
организациях. Фактически, как свидетельство качества технологии, лежащей в основе Lint, 
множество различных версий продукта по-прежнему доступны сегодня. %TODO: Add links to products

\subsection{Второе поколение статических анализаторов}
Почти два десятилетия статический анализ оставался скорее областью научных исследований, чем коммерчески 
жизнеспособным производственным инструментом для выявления дефектов. В начале 2000 года
появилось второе поколение инструментов. Используя новые 
технологии, оно расширяло возможности инструментов первого поколения от простого выявления 
нежелательных паттернов до покрытия путей выполнения. Эти инструменты могли анализировать 
целые базы кода, а не только один файл. 

Сместив фокус с «подозрительных конструкций» на «дефекты времени выполнения», разработчики 
статического анализа осознали необходимость в большем понимания внутреннего 
устройстава программ. Это означало объединение сложного анализа путей с межпроцедурным анализом, 
чтобы понять, что происходит, когда поток управления переходит от одной функции к другой в 
рамках данной программы.

Несмотря на принятие и использование организациями, статический анализ 2-го поколения все еще 
не мог найти золотую середину между точностью и масштабируемостью. Некоторые решения были 
точными для небольшого набора типов дефектов, но не могли масштабироваться для анализа 
миллионов строк кода. Другие могли работать за короткое время, но имели показатели точности, 
аналогичные Lint, представляя похожие проблемы с предупреждениями об ошибках и шумом. После 
внедрения в процесс разработки эти инструменты могут сообщать о дефектах в приемлемом 
соотношении, но только с ограниченными параметрами анализа. 

Инструментам второго поколения требовались однородные среды сборки и разработки. 
Из-за этого внедрить их в какой то проект было сложной задачей, требовавшей больших усилий.

Борьба между точностью и маcштабируемостью вылилась в проблему с ложными срабатываниями. Подобно 
шуму, от которого страдали инструменты первого поколения, ложные срабатывания тормозили 
распространению инструментов второго поколения. 

\subsection{Третье поколение статических анализаторов}
Третье поколение инструментов статической проверки программ превосходит своих предшественников по
всем параметрам и является неотъемлемой частью процессов и сред разработки. Одной из причин подобного успеха является использование решателей для
задач выполнимости булевых формул (SAT) совместно с традиционными техниками анализа.\cite{}

Новаторское использование SAT позволяет статическому анализу исходного кода находить правильные дефекты 
в коде без большого количест ложных срабатываний.

\section{Уровни статического анализа кода}

\subsection{Бинарный уровень}
Предметом статического анализа могут выступать исходный код, промежуточное представление, ассеблерный код или
бинарный код. То есть на любом этапе до выполнения программы. Часто статический анализ примеменяется на исходном коде
или промежуточном представлении, таком как  Static Single Assignment (SSA). Код высокого уровня содержит множество 
структурированной информации, что упрощает анализ. Тем не менее статический анализ бинарного кода, набирает популярность 
благодаря нескольким тенденциям в разработке программного обеспечения. Первый тренд заключается в расширении 
функциональности программного обеспечения за счет интеграции надежного кода с ненадежным внешним кодом. Вторая тенденция - 
разработка программного обеспечения на основе компонентов для повышения производительности и контроля затрат.
Несколько модулей от разных производителей объединены в единую систему. Изоляция неисправностей модулей от разных производителей жизненно важна для устойчивости всей системы.
Как правило, статический анализ на двоичном уровне необходим по следующим причинам\cite{Zeng2012StaticAO}:
\begin{enumerate}
        \item Исходный код недоступен. Для вредоносного кода, такого как вирусы, черви, бот-сети, троянские кони и 
            ненадежные расширения, такие как плагины браузера, надстройки баз данных и другой ненадежный код, исходный код 
            либо недоступен, либо ненадежен. 
        \item Возможно, компилятор неверен. Компилятор может намеренно или непреднамеренно сгенерировать неверный или 
            неточный код. Иногда оптимизирующие компиляторы оптимизируют код настолько агрессивно, что семантика двоичного 
            кода может отличаться от семантики исходного кода. Подобная ситуация может потребовать выполнить проверку 
            перевода сгенерированного кода.
        \item Перезапись безопасности неуместна на уровне источника или IR. Некоторые стратегии безопасности анализируют и 
            вставляют проверки безопасности в двоичный код для защиты рассматриваемого двоичного кода. Эти подходы должны 
            идентифицировать определенные машинные инструкции в двоичном коде и вставлять динамические проверки 
            безопасности прямо перед ними. На исходном уровне или уровне IR машинные инструкции даже не генерируются.
        \item Некоторые оптимизации могут быть выполнены на двоичном уровне для повышения производительности во время  
            выполнения программы. Хотя большинство программных оптимизаций выполняется на промежуточных представлениях во 
            время компиляции, некоторые системы оптимизируют двоичный код напрямую без информации об исходном коде или с  
            ее ограничением, например Valgrind\cite{Valgrind2008}.
        \item Двоичный код можно повторно использовать напрямую, без исходного кода. Иногда исходный код теряется, 
            недоступен или больше не поддерживается его первоначальными авторами, и было бы полезно иметь возможность 
            повторно использовать двоичный код напрямую.
\end{enumerate}

Причины для проведения статического анализа двоичного кода вместо исходного кода или промежуточных представлений, которые 
перечислены выше, далеки от завершения.

К стратениям проведения статического анализа на бинарном коде относятся\cite{Zeng2012StaticAO}:
\begin{enumerate}
    \item Дизассемблеры. Дизассемблер используется для декодирования информации, хранящейся в двоичных файлах, и перевода 
        машинных инструкций на язык ассемблера или эквивалентное промежуточное представление. В принципе, методы 
        дизассемблирования можно разделить на две категории: методы динамической разборки и методы статической разборки в 
        зависимости от того, выполняется ли двоичный код или нет. 
    \item Построение графа потока управления. После дизассемблирования двоичного кода следующим шагом является построение 
        графа потока управления или конкретизация скелета графа потока управления, если он уже был сгенерирован во время
        разборки. Как правило, в двоичном коде нет явной информации о потоке управления. Все нужно извлечь из самого 
        двоичного кода. Существует несколько алгоритмов построения графа потока управления. Для ребер, вызванных 
        инструкциями прямого перехода и вызова, дизассемблер может легко идентифицировать их цели(targets) и добавлять 
        ребра для них в граф потока управления. Например, IDA Pro\cite{10.5555/1481438} создает граф потока управления с ребрами, 
        индуцированными только инструкциями прямого перехода и вызова. 
    \item К прочим стратегиям стоит отнести разбор регистров флагов и анализ алиасов.
\end{enumerate}

\subsection{Уровень промежуточного представления}
Компиляция программы - сложный процесс. Компилятор - это программа, которая переводит высокоуровневую программу на исходном языке в форму, готовую к 
выполнению на компьютере. На раннем этапе развития компиляторов разработчики ввели IR - intermediate representation (промежуточные представления, 
также обычно называемые промежуточными языками) для управления сложностью процесса компиляции. Использование IR в качестве внутреннего представления 
программы позволяет разбить компилятор на несколько этапов и компонентов, тем самым извлекая выгоду из модульности. Одним из наиболее популярных 
промежуточных представлений является LLVM IR.

Проект LLVM - это набор модульных технологий, компиляторов и множество инструментов. LLVM начинался как исследовательский проект в Университете 
Иллинойса с целью предоставить современную стратегию компиляции на основе SSA, способную поддерживать как статическую, так и динамическую компиляцию 
произвольных языков программирования. С тех пор LLVM превратился в зонтичный проект, состоящий из ряда подпроектов, многие из которых используются в 
производстве в большом количестве коммерческих проектов и проектов с открытым исходным кодом, а также широко используются в академических 
исследованиях\cite{Chow2013IR}.

В \cite{10.1007/978-3-642-27705-4_12} выделяют следующие преимущества статического анализа промежуточного представления LLVM IR языков высокого уровня (С/С++):
\begin{enumerate}
    \item Анализируемая программа намного ближе к программе, которая фактически выполняется на компьютере, поскольку неоднозначности семантики уже 
          устранены. 
    \item Появляется возможность находить ошибки, внесенные компилятором.
    \item Использование компилятора IR делает возможным выполнение анализа для программ, написанных на различных языках программирования.
\end{enumerate}

Программы в LLVM-IR представляют собой SSA (static single assignment), то есть, каждой (скалярной) переменной значение присваивается ровно один раз.
Таким образом, присвоение значения скалярным переменным можно рассматривать как логические эквивалентности. SSA располагает ограниченным набором 
используемых инструкций и  низкоуровневым характером, что позволяет произвести преобразование программы LLVM-IR в логическое представление значительно 
проще, по сравнению с подобными преобразованиями для исходного кода языка программирования высокого уровня\cite{10.1007/978-3-642-27705-4_12}.

%TODO Add more info

\subsection{Уровень ассемблерного кода}
TODO
        
\subsection{Уровень исходного кода}
TODO

\section{Динамические анализаторы}
TODO

\section{Подходы к проверке качества инстурментов анализа программ}


\FloatBarrier
